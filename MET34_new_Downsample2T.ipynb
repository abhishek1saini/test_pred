{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek1saini/test_pred/blob/test1/MET34_new_Downsample2T.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u_tP_EjJuo2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eabde41f-7671-4460-b82e-656b55fbbae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m112.6/128.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BQilwakLxMBg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, Dense, TimeDistributed\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,mean_absolute_percentage_error\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrJc6l4W4Wes",
        "outputId": "6ce121f4-d58d-4fee-f8c5-1fff1aeb9fa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SosGyg0AuumZ"
      },
      "outputs": [],
      "source": [
        "from keras_tuner import HyperParameters\n",
        "from keras_tuner import HyperModel\n",
        "from keras_tuner.tuners import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9EGICn6PGT2i"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Handling missing, filling with values from previous day\"\"\"\n",
        "def handle_missing(multi_tr_data):\n",
        "  #multi_tr_data = multi_tr_data.set_index('timestamp')\n",
        "  for col in multi_tr_data.columns.to_list():\n",
        "    for header,series in multi_tr_data[multi_tr_data[col].isna()==True].items():\n",
        "        for dt, value in series.items():\n",
        "            prev_dt = dt - timedelta(days=1)\n",
        "            multi_tr_data.loc[dt][col] = multi_tr_data.loc[prev_dt][col]\n",
        "  return multi_tr_data\n",
        "\n",
        "def scale_data(train_data, test_data, val_data):\n",
        "  #scaler = MinMaxScaler()\n",
        "  scaler = StandardScaler()\n",
        "  t_train = scaler.fit_transform(train_data)\n",
        "  t_val = scaler.transform(val_data)\n",
        "  t_test = scaler.transform(test_data)\n",
        "  return t_train, t_val, t_test, scaler\n",
        "\n",
        "def train_test_split(multi_tr_data, test_ratio):\n",
        "  total_samples = len(multi_tr_data)\n",
        "  train_samples = int((total_samples)*(1-(test_ratio*2)))\n",
        "  test_samples=val_samples = int(total_samples*test_ratio)\n",
        "  train_data = multi_tr_data.iloc[:train_samples].copy(deep=True)\n",
        "  val_data = multi_tr_data[train_samples:train_samples+val_samples].copy(deep=True)\n",
        "  test_data = multi_tr_data[train_samples+val_samples:].copy(deep=True)\n",
        "  return train_data, val_data, test_data\n",
        "\n",
        "def prep_data(dataset, window, horizon, original_df):\n",
        "  X, y = [], []\n",
        "  y_tr_dates = []\n",
        "  y_ts_dates = []\n",
        "  series_len = len(dataset)\n",
        "  end = series_len - horizon\n",
        "  for win_start in range(series_len):\n",
        "    x_end = win_start + window\n",
        "    y_end = x_end + horizon\n",
        "    if y_end > series_len:\n",
        "      break\n",
        "    X.append(dataset[win_start:x_end,:])\n",
        "    y.append(dataset[x_end:y_end,:])\n",
        "    y_ts_dates.append(original_df[x_end:y_end].index)\n",
        "  return np.array(X), np.array(y), np.expand_dims(np.array(y_ts_dates), axis=2)[:,0,:], y_ts_dates\n",
        "\n",
        "#Preapare the tensors\n",
        "def prepare_tensors(train: tuple, validation: tuple, batch_size: int, shuffle_buffer_size=1000):\n",
        "  train_set = tf.data.Dataset.from_tensor_slices(train)\n",
        "  train_set = train_set.cache().shuffle(shuffle_buffer_size).batch(batch_size)\n",
        "  val_set = tf.data.Dataset.from_tensor_slices(validation)\n",
        "  val_set = val_set.cache().shuffle(shuffle_buffer_size).batch(batch_size)\n",
        "  print(f\"Train Tensor {train_set.element_spec}\\nValidation Tensor Spec {val_set.element_spec}\")\n",
        "  return train_set, val_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3_3M6C_eKyAr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "ae3978d3-5ecc-454c-af38-7e2497125241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     capacity_instance_ceph_rbd_ops_read_avg  \\\n",
              "timestamp                                                      \n",
              "2023-10-25 13:58:00                                 8.484722   \n",
              "2023-10-25 14:00:00                                 8.815000   \n",
              "2023-10-25 14:02:00                                 8.768964   \n",
              "2023-10-25 14:04:00                                 8.172521   \n",
              "2023-10-25 14:06:00                                 7.014163   \n",
              "\n",
              "                     capacity_instance_ceph_rbd_ops_write_avg  \n",
              "timestamp                                                      \n",
              "2023-10-25 13:58:00                                 15.562625  \n",
              "2023-10-25 14:00:00                                 16.850598  \n",
              "2023-10-25 14:02:00                                 16.013675  \n",
              "2023-10-25 14:04:00                                 15.147301  \n",
              "2023-10-25 14:06:00                                 13.832236  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb9f561c-5102-4455-b523-f50df7521702\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>capacity_instance_ceph_rbd_ops_read_avg</th>\n",
              "      <th>capacity_instance_ceph_rbd_ops_write_avg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-10-25 13:58:00</th>\n",
              "      <td>8.484722</td>\n",
              "      <td>15.562625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-25 14:00:00</th>\n",
              "      <td>8.815000</td>\n",
              "      <td>16.850598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-25 14:02:00</th>\n",
              "      <td>8.768964</td>\n",
              "      <td>16.013675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-25 14:04:00</th>\n",
              "      <td>8.172521</td>\n",
              "      <td>15.147301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-25 14:06:00</th>\n",
              "      <td>7.014163</td>\n",
              "      <td>13.832236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb9f561c-5102-4455-b523-f50df7521702')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb9f561c-5102-4455-b523-f50df7521702 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb9f561c-5102-4455-b523-f50df7521702');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f91821e1-4045-4b69-87ab-cc94ad285d03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f91821e1-4045-4b69-87ab-cc94ad285d03')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f91821e1-4045-4b69-87ab-cc94ad285d03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "window_size=320\n",
        "# BATCH_SIZE=64\n",
        "features = 2\n",
        "horizon=30\n",
        "shuffle_buffer_size = 10000\n",
        "\n",
        "#raw_data = pd.read_csv('/content/drive/MyDrive/Data/Marjan_ceph_metrics_w8.csv')\n",
        "raw_data = pd.read_csv('/content/drive/MyDrive/Data/ceph-marjan_custom_timeline_80d_9h.csv')\n",
        "raw_data = raw_data.tail(50000)\n",
        "#raw_data = raw_data.drop('Unnamed: 0', axis=1)\n",
        "raw_data['timestamp'] = pd.to_datetime(raw_data['timestamp'])\n",
        "raw_data.set_index('timestamp', inplace=True)\n",
        "multi_data = raw_data[['capacity_instance_ceph_rbd_ops_read_avg', 'capacity_instance_ceph_rbd_ops_write_avg']]\n",
        "multi_data = multi_data.resample('2T').mean()\n",
        "#multi_data = multi_data[['date', 'OR', 'OW']]\n",
        "multi_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_tr_data = multi_data\n",
        "# multi_tr_data = multi_data[(multi_data.timestamp >= '2023-05-13 04:18:00') & (multi_data.timestamp <= '2023-05-24')].copy(deep=True)\n",
        "multi_tr_data = handle_missing(multi_tr_data)\n",
        "train_data, val_data, test_data,  = train_test_split(multi_tr_data, test_ratio=0.1)\n",
        "t_train,t_val, t_test, ts_scaler = scale_data(train_data, test_data, val_data)\n",
        "print(f\"Shape of Train set : {t_train.shape}\\nShape of Test set : {t_test.shape}\\nShape of Validation set : {t_val.shape}\")\n",
        "\n",
        "X_train, y_train, tr_dates, date1 = prep_data(t_train, window=window_size, horizon=horizon, original_df=train_data)\n",
        "X_val, y_val, val_dates, date2 = prep_data(t_val, window=window_size, horizon=horizon, original_df=val_data)\n",
        "X_test, y_test, ts_dates, date3  = prep_data(t_test, window=window_size, horizon=horizon, original_df=test_data)\n",
        "print(f\"Shape of X-train : {X_train.shape}, y-train: {y_train.shape}\\nShape of X-val : {X_val.shape}, y-val: {y_val.shape}\\nShape of X-test : {X_test.shape}, y-test: {y_test.shape}\\n\")\n",
        "print(\"ts_dates for test data: \", type(ts_dates), np.shape(ts_dates))\n",
        "print(type(date1), type(date2), type(date3))\n",
        "print(len(date1), len(date2), len(date3))\n",
        "print(\"ts_dates:\", ts_dates[0])\n",
        "print(Input(X_train.shape[-2:]))\n",
        "# train_set, val_set = prepare_tensors(train=(X_train, y_train), validation=(X_val, y_val), batch_size=BATCH_SIZE, shuffle_buffer_size=shuffle_buffer_size)\n",
        "train_set = (X_train, y_train)\n",
        "val_set = (X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJTzuqp032Pi",
        "outputId": "45c6cdb1-c6d8-4b3e-ace1-7c8440448f2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Train set : (20000, 2)\n",
            "Shape of Test set : (2500, 2)\n",
            "Shape of Validation set : (2500, 2)\n",
            "Shape of X-train : (19651, 320, 2), y-train: (19651, 30, 2)\n",
            "Shape of X-val : (2151, 320, 2), y-val: (2151, 30, 2)\n",
            "Shape of X-test : (2151, 320, 2), y-test: (2151, 30, 2)\n",
            "\n",
            "ts_dates for test data:  <class 'numpy.ndarray'> (2151, 1)\n",
            "<class 'list'> <class 'list'> <class 'list'>\n",
            "19651 2151 2151\n",
            "ts_dates: ['2023-11-26T06:38:00.000000000']\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 320, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "63E_FR-uvLhK"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "class seq_HyperModel(HyperModel):\n",
        "  def build(self, hp):\n",
        "    tf.keras.backend.clear_session()\n",
        "    # features = 6\n",
        "    hidden_units = hp.Int('hidden_units', min_value=64, max_value=512, step=10, sampling='linear')\n",
        "    dropout_range = hp.Float('dropout', min_value=0.0, max_value=0.2, step=0.1, sampling='linear')\n",
        "    dropout_enc_0 = hp.Float('dropout_enc_0', min_value=0.0, max_value=0.3, step=0.1, sampling='linear')\n",
        "    dropout_dec_0 = hp.Float('dropout_dec_0', min_value=0.0, max_value=0.3, step=0.1, sampling='linear')\n",
        "    kernel_initializer = hp.Choice('kernel_initializer', ['he_uniform'])\n",
        "    batch_size_range = hp.Int('batch_size', min_value=32, max_value=128)\n",
        "    learning_rate_range = hp.Float('learning_rate', min_value=1e-6, max_value=1e-3, step=10, sampling='log')\n",
        "    #learning_rate_range = hp.Choice('learning_rate', [0.00001, 0.000001, 0.0001])\n",
        "    dense_activation = hp.Choice('dense_activation', ['linear'], default=None)\n",
        "    optimizer_choice = hp.Choice('optimizer_choice',['adamw', 'sgd'])\n",
        "    n_layers = hp.Int('n_layers', min_value=1, max_value=6, step=1, sampling='linear')\n",
        "    momemtum_range = hp.Float('momemtum_range', min_value=0.0, max_value=0.4, step=0.1, sampling='linear')\n",
        "    loss_func_choice = hp.Choice('loss_function', ['mse', 'huber'])\n",
        "    input = Input(shape=X_train.shape[-2:])\n",
        "    lstm1 = LSTM(hidden_units, return_state=True, dropout=dropout_range, kernel_initializer=kernel_initializer)\n",
        "    st_hidden_, st_hidden, st_cell = lstm1(input)\n",
        "    repeat = RepeatVector(horizon)\n",
        "    enc_out = repeat(st_hidden_)\n",
        "    lstm2 = LSTM(hidden_units, return_sequences=True, dropout=dropout_range,  kernel_initializer=kernel_initializer)\n",
        "    dec_out = lstm2(enc_out, initial_state=[st_hidden, st_cell])\n",
        "\n",
        "    with hp.conditional_scope(\"dense_activation\", [\"None\"]):\n",
        "      if dense_activation == \"None\":\n",
        "        dense = TimeDistributed(Dense(features, activation=None))\n",
        "\n",
        "    with hp.conditional_scope(\"dense_activation\", [\"linear\"]):\n",
        "      if dense_activation == \"linear\":\n",
        "        dense = TimeDistributed(Dense(features, activation='linear'))\n",
        "\n",
        "    final_out = dense(dec_out)\n",
        "    model = Model(input, final_out)\n",
        "\n",
        "    with hp.conditional_scope('optimizer_choice',[\"adam\"]):\n",
        "      if optimizer_choice == 'adam':\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_range)\n",
        "\n",
        "    with hp.conditional_scope('optimizer_choice',[\"adamw\"]):\n",
        "      if optimizer_choice == 'adamw':\n",
        "        optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate_range)\n",
        "\n",
        "    with hp.conditional_scope('optimizer_choice',[\"rmsprop\"]):\n",
        "      if optimizer_choice == 'rmsprop':\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate_range, momentum=momemtum_range)\n",
        "\n",
        "    with hp.conditional_scope('optimizer_choice',[\"sgd\"]):\n",
        "      if optimizer_choice == 'sgd':\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate_range, momentum=momemtum_range)\n",
        "    model.compile(loss=loss_func_choice,\n",
        "                  # optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_range),\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['mse',tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "  def fit(self, hp, model, train_tuple, val_tuple, *args, **kwargs):\n",
        "    batch_size_range = hp.Int('batch_size', min_value=8, max_value=128, step=8)\n",
        "    train_set, val_set = prepare_tensors(train=(X_train, y_train), validation=(X_val, y_val), batch_size=batch_size_range, shuffle_buffer_size=shuffle_buffer_size)\n",
        "    return model.fit(train_set, validation_data=val_set, *args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vLXIvj8pJp7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b0b83c-1bfa-4991-b4cd-825ba6e26db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 12\n",
            "hidden_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 10, 'sampling': 'linear'}\n",
            "dropout (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.2, 'step': 0.1, 'sampling': 'linear'}\n",
            "dropout_enc_0 (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n",
            "dropout_dec_0 (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n",
            "kernel_initializer (Choice)\n",
            "{'default': 'he_uniform', 'conditions': [], 'values': ['he_uniform'], 'ordered': False}\n",
            "batch_size (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 1, 'sampling': 'linear'}\n",
            "learning_rate (Float)\n",
            "{'default': 1e-06, 'conditions': [], 'min_value': 1e-06, 'max_value': 0.001, 'step': 10, 'sampling': 'log'}\n",
            "dense_activation (Choice)\n",
            "{'default': 'linear', 'conditions': [], 'values': ['linear'], 'ordered': False}\n",
            "optimizer_choice (Choice)\n",
            "{'default': 'adamw', 'conditions': [], 'values': ['adamw', 'sgd'], 'ordered': False}\n",
            "n_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 6, 'step': 1, 'sampling': 'linear'}\n",
            "momemtum_range (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.4, 'step': 0.1, 'sampling': 'linear'}\n",
            "loss_function (Choice)\n",
            "{'default': 'mse', 'conditions': [], 'values': ['mse', 'huber'], 'ordered': False}\n"
          ]
        }
      ],
      "source": [
        "hp = HyperParameters()\n",
        "bayesian_tuner = BayesianOptimization(\n",
        "                    hypermodel = seq_HyperModel(),\n",
        "                    objective = \"val_loss\",\n",
        "                    max_trials = 30,\n",
        "                    #num_initial_points = 20,\n",
        "                    alpha = 0.0001, # represents the expected amount of noise in the observed performances in Bayesian optimization.\n",
        "                    beta = 2.6, #  the balancing factor of exploration and exploitation. The larger it is, the more explorative it is\n",
        "                    hyperparameters = hp,\n",
        "                    **{\"tuner_id\" : \"BayesianOptimization\",\n",
        "                      \"overwrite\" : True,\n",
        "                      \"project_name\" : \"bayesian_optimization\"}\n",
        "                    )\n",
        "bayesian_tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUqN_3zZM6Jk",
        "outputId": "dc776ba4-b0bc-485f-d05d-d8cf97a959a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 19 Complete [00h 05m 22s]\n",
            "val_loss: 0.7951688766479492\n",
            "\n",
            "Best val_loss So Far: 0.16051915287971497\n",
            "Total elapsed time: 01h 30m 25s\n",
            "\n",
            "Search: Running Trial #20\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "344               |174               |hidden_units\n",
            "0.1               |0.1               |dropout\n",
            "0.2               |0                 |dropout_enc_0\n",
            "0.1               |0.2               |dropout_dec_0\n",
            "he_uniform        |he_uniform        |kernel_initializer\n",
            "77                |109               |batch_size\n",
            "1e-06             |0.001             |learning_rate\n",
            "linear            |linear            |dense_activation\n",
            "sgd               |adamw             |optimizer_choice\n",
            "6                 |6                 |n_layers\n",
            "0.1               |0.3               |momemtum_range\n",
            "huber             |huber             |loss_function\n",
            "\n",
            "Train Tensor (TensorSpec(shape=(None, 320, 2), dtype=tf.float64, name=None), TensorSpec(shape=(None, 30, 2), dtype=tf.float64, name=None))\n",
            "Validation Tensor Spec (TensorSpec(shape=(None, 320, 2), dtype=tf.float64, name=None), TensorSpec(shape=(None, 30, 2), dtype=tf.float64, name=None))\n",
            "Epoch 1/20\n",
            "256/256 [==============================] - 17s 56ms/step - loss: 0.3246 - mse: 0.9574 - root_mean_squared_error: 0.9785 - val_loss: 0.4328 - val_mse: 1.1507 - val_root_mean_squared_error: 1.0727\n",
            "Epoch 2/20\n",
            "256/256 [==============================] - 14s 54ms/step - loss: 0.3247 - mse: 0.9566 - root_mean_squared_error: 0.9780 - val_loss: 0.4327 - val_mse: 1.1503 - val_root_mean_squared_error: 1.0725\n",
            "Epoch 3/20\n",
            "256/256 [==============================] - 14s 53ms/step - loss: 0.3239 - mse: 0.9552 - root_mean_squared_error: 0.9773 - val_loss: 0.4325 - val_mse: 1.1499 - val_root_mean_squared_error: 1.0723\n",
            "Epoch 4/20\n",
            "256/256 [==============================] - 14s 54ms/step - loss: 0.3239 - mse: 0.9554 - root_mean_squared_error: 0.9774 - val_loss: 0.4324 - val_mse: 1.1495 - val_root_mean_squared_error: 1.0721\n",
            "Epoch 5/20\n",
            "256/256 [==============================] - 14s 54ms/step - loss: 0.3237 - mse: 0.9538 - root_mean_squared_error: 0.9766 - val_loss: 0.4322 - val_mse: 1.1491 - val_root_mean_squared_error: 1.0719\n",
            "Epoch 6/20\n",
            "256/256 [==============================] - 14s 53ms/step - loss: 0.3239 - mse: 0.9553 - root_mean_squared_error: 0.9774 - val_loss: 0.4321 - val_mse: 1.1487 - val_root_mean_squared_error: 1.0718\n",
            "Epoch 7/20\n",
            "256/256 [==============================] - 14s 54ms/step - loss: 0.3235 - mse: 0.9548 - root_mean_squared_error: 0.9771 - val_loss: 0.4320 - val_mse: 1.1483 - val_root_mean_squared_error: 1.0716\n",
            "Epoch 8/20\n",
            "256/256 [==============================] - 14s 53ms/step - loss: 0.3235 - mse: 0.9544 - root_mean_squared_error: 0.9769 - val_loss: 0.4318 - val_mse: 1.1479 - val_root_mean_squared_error: 1.0714\n",
            "Epoch 9/20\n",
            "256/256 [==============================] - 14s 54ms/step - loss: 0.3232 - mse: 0.9536 - root_mean_squared_error: 0.9765 - val_loss: 0.4317 - val_mse: 1.1475 - val_root_mean_squared_error: 1.0712\n",
            "Epoch 10/20\n",
            "256/256 [==============================] - 14s 54ms/step - loss: 0.3233 - mse: 0.9541 - root_mean_squared_error: 0.9768 - val_loss: 0.4315 - val_mse: 1.1471 - val_root_mean_squared_error: 1.0710\n",
            "Epoch 11/20\n",
            "256/256 [==============================] - 14s 54ms/step - loss: 0.3232 - mse: 0.9535 - root_mean_squared_error: 0.9765 - val_loss: 0.4314 - val_mse: 1.1467 - val_root_mean_squared_error: 1.0708\n",
            "Epoch 12/20\n",
            "256/256 [==============================] - 14s 53ms/step - loss: 0.3230 - mse: 0.9523 - root_mean_squared_error: 0.9759 - val_loss: 0.4313 - val_mse: 1.1463 - val_root_mean_squared_error: 1.0706\n",
            "Epoch 13/20\n",
            "256/256 [==============================] - 14s 53ms/step - loss: 0.3227 - mse: 0.9526 - root_mean_squared_error: 0.9760 - val_loss: 0.4311 - val_mse: 1.1459 - val_root_mean_squared_error: 1.0705\n",
            "Epoch 14/20\n",
            "256/256 [==============================] - 14s 54ms/step - loss: 0.3230 - mse: 0.9532 - root_mean_squared_error: 0.9763 - val_loss: 0.4310 - val_mse: 1.1455 - val_root_mean_squared_error: 1.0703\n",
            "Epoch 15/20\n",
            " 24/256 [=>............................] - ETA: 11s - loss: 0.3780 - mse: 1.1748 - root_mean_squared_error: 1.0839"
          ]
        }
      ],
      "source": [
        "bayesian_tuner.search(train_tuple = train_set, val_tuple = val_set, steps_per_epoch = None, shuffle = False, epochs=20,\n",
        "                      # validation_split = 0.20,\n",
        "                      verbose = 1, #\n",
        "                      use_multiprocessing = True,\n",
        "                    )\n",
        "bayesian_tuner.get_best_hyperparameters()[0].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_K7EjpYPVl3"
      },
      "outputs": [],
      "source": [
        "bayesian_tuner.results_summary(num_trials=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO1R4NihQWcx"
      },
      "outputs": [],
      "source": [
        "trials = bayesian_tuner.oracle.get_best_trials(num_trials=15)\n",
        "HP_list = []\n",
        "for trial in trials:\n",
        "    HP_list.append(trial.hyperparameters.get_config()[\"values\"] | {\"Score\": trial.score})\n",
        "HP_df = pd.DataFrame(HP_list)\n",
        "#HP_df.to_csv(\"name.csv\", index=False, na_rep='NaN')\n",
        "#HP_df.to_csv(\"/content/drive/MyDrive/bayesian_tuner-marjan_25_08_2023.csv\", index=False, na_rep='NaN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJI7VMqPSmT5"
      },
      "outputs": [],
      "source": [
        "#Build model with best HP\n",
        "bayesian_best_model = bayesian_tuner.hypermodel.build(bayesian_tuner.get_best_hyperparameters()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_R9sYV0S3HU"
      },
      "outputs": [],
      "source": [
        "bayesian_best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXx3Q0-bV-KK"
      },
      "outputs": [],
      "source": [
        "#bayesian_best_model.save(\"/content/drive/MyDrive/bayesian_tuner_marjan_model_25_08_2023\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HP_df.head()"
      ],
      "metadata": {
        "id": "G4dhAsWo8Fyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWUVugJd8k-r"
      },
      "outputs": [],
      "source": [
        "params = HP_df.iloc[0]\n",
        "# hidden_units\tdropout\tkernel_initializer\tbatch_size\tlearning_rate\tdense_activation\toptimizer_choice\tn_layers\tmomemtum_range\tloss_function\tScore\n",
        "# 274\t            0.1\t    he_uniform\t        96\t        0.00001\t      linear\t            adamw\t            3\t        0.7\t            mse\t      0.005235\n",
        "# 384\t            0.1\t    he_uniform\t        107\t        0.00001\t      None\t              adamw\t            5\t        0.5\t            mse\t      0.005237\n",
        "\n",
        "#For 120-30 horizon\n",
        "# 294 \t0.0 \t0.4 \t0.3 \the_uniform \t36 \t0.00001 \tNone \tadamw \t2 \t0.3 \tmse \t0.004750\n",
        "# 484 \t0.1 \t0.4 \t0.3 \the_uniform \t38 \t0.00001 \tlinear \tadamw \t2 \t0.8 \tmse \t0.004791\n",
        "# 404 \t0.1 \t0.2 \t0.2 \the_uniform \t44 \t0.00001 \tlinear \tadamw \t2 \t0.4 \tmse \t0.004843\n",
        "\n",
        "#For 120-30 horizon with linear learning rate\n",
        "# 454 \t0.2 \t0.1 \t0.3 \the_uniform \t56 \t0.000201 \tNone \tadamw \t4 \t0.7 \tmse \t0.004770\n",
        "# 194 \t0.2 \t0.0 \t0.4 \the_uniform \t35 \t0.000701 \tlinear \tadamw \t3 \t0.4 \tmse \t0.004792\n",
        "# 304 \t0.1 \t0.0 \t0.2 \the_uniform \t123 \t0.000451 \tNone \tadamw \t3 \t0.2 \tmse \t0.004807"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ICqnm28wBz"
      },
      "outputs": [],
      "source": [
        "#params['dropout'] = 0.2\n",
        "#params[\"dropout_enc_0\"] = 0.0\n",
        "#params[\"dropout_dec_0\"] = 0.2\n",
        "#params['batch_size'] = 60\n",
        "#params['hidden_units'] = 60\n",
        "#params['learning_rate'] = 0.001\n",
        "#params['optimizer_choice'] = 'adam'\n",
        "\n",
        "'''params = {\n",
        "    'hidden_units':          274,\n",
        "'dropout':                      0.1,\n",
        "'kernel_initializer':    'he_uniform',\n",
        "'batch_size':                   107,\n",
        "'learning_rate':              0.00001,\n",
        "'dense_activation':          'linear',\n",
        "'optimizer_choice':         'adamw',\n",
        "'momemtum_range':               0.7,\n",
        "'loss_function':              'mse',\n",
        "'dropout_enc_0':                0.0,\n",
        "'dropout_dec_0':                0.3,\n",
        "'n_layers':                     4\n",
        "}'''\n",
        "\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2aXLqMivanQ"
      },
      "outputs": [],
      "source": [
        "def encoder_decoder_model(params):\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  hidden_units = params.get('hidden_units')\n",
        "  n_layers = params.get('n_layers')\n",
        "  dense_activation = 'linear'\n",
        "  loss_func_choice = params.get('loss_function')\n",
        "  learning_rate = params.get('learning_rate')\n",
        "  encoder_output = []\n",
        "  kernel_initializer = params.get('kernel_initializer')\n",
        "  input = Input(shape=X_train.shape[-2:])\n",
        "  if n_layers > 1:\n",
        "    enc_out = LSTM(units=hidden_units,\n",
        "                      return_state=True,\n",
        "                      return_sequences=True,\n",
        "                      dropout=params.get('dropout_enc_0'),\n",
        "                      kernel_initializer = kernel_initializer,\n",
        "                      use_bias=True,\n",
        "                      unit_forget_bias=params.get(\"enc_lstm_0_unit_forget_bias\"),\n",
        "                      name=f\"encoder_lstm_0\")(input)\n",
        "    encoder_output.append(enc_out)\n",
        "    # for i in np.arange(1, hp.get('n_layers')-1):\n",
        "    for i in np.arange(1, n_layers-1):\n",
        "      enc_out = ( LSTM(units=hidden_units,\n",
        "                  return_state=True,\n",
        "                  return_sequences=True,\n",
        "                  #dropout=params.get(f'dropout_enc_{i-1}'),\n",
        "                  dropout= 0.0,\n",
        "                  # kernel_initializer = hp.Choice(f'kern_init_enc_lstm_{i}', [\"glorot_uniform\", 'he_uniform']),\n",
        "                  kernel_initializer = kernel_initializer,\n",
        "                  use_bias=True,\n",
        "                  unit_forget_bias=params.get(f\"enc_lstm_{i}_unit_forget_bias\"),\n",
        "                  name=f\"encoder_lstm_{i}\")(encoder_output[i-1][0] )\n",
        "                )\n",
        "      encoder_output.append(enc_out)\n",
        "    enc_out = LSTM(units=hidden_units,\n",
        "                    return_state=True,\n",
        "                    #dropout=params.get(f'dropout_enc_{n_layers-1}'),\n",
        "                    dropout = 0.0,\n",
        "                  #  kernel_initializer = hp.Choice(f'kern_init_enc_lstm_{n_layers-1}', [\"glorot_uniform\", 'he_uniform']),\n",
        "                    kernel_initializer = kernel_initializer,\n",
        "                    use_bias=True,\n",
        "                    unit_forget_bias=params.get(f\"enc_lstm_{n_layers-1}_unit_forget_bias\"),\n",
        "                    name=f\"encoder_lstm_{n_layers-1}\")(encoder_output[-1][0])\n",
        "    encoder_output.append(enc_out)\n",
        "  else:\n",
        "    enc_out = LSTM(units=hidden_units,\n",
        "                    return_state=True,\n",
        "                    dropout=params.get('dropout_enc_0'),\n",
        "                    kernel_initializer = kernel_initializer,\n",
        "                    use_bias=True,\n",
        "                    unit_forget_bias=params.get(f\"enc_lstm_0_unit_forget_bias\"),\n",
        "                    name=f\"encoder_lstm_{0}\")(input)\n",
        "    encoder_output.append(enc_out)\n",
        "  repeat = RepeatVector(horizon)\n",
        "  dec_in = repeat(encoder_output[-1][0])\n",
        "  dec_out = LSTM(units=hidden_units,\n",
        "                  return_sequences=True,\n",
        "                  dropout=params.get('dropout_dec_0'),\n",
        "                  kernel_initializer = kernel_initializer,\n",
        "                  use_bias=True,\n",
        "                  unit_forget_bias=params.get(f\"dec_lstm_0_unit_forget_bias\"),\n",
        "                  name='decoder_lstm_0')(dec_in,initial_state=encoder_output[0][1:])\n",
        "  dec_out = tf.keras.layers.ReLU()(dec_out)\n",
        "  if n_layers > 1:\n",
        "    # for i in np.arange(1, hp.get('n_layers')):\n",
        "    for i in np.arange(1, n_layers-1):\n",
        "      dec_out = LSTM(units=hidden_units,\n",
        "                    return_sequences=True,\n",
        "                    #dropout=params.get(f'dropout_dec_{i}'),\n",
        "                    dropout = 0.0,\n",
        "                    use_bias=True,\n",
        "                    unit_forget_bias=params.get(f\"dec_lstm_{i}_unit_forget_bias\"),\n",
        "\n",
        "                    kernel_initializer = kernel_initializer,\n",
        "                    name=f\"decoder_lstm_{i}\")(dec_out, initial_state=encoder_output[i][1:])\n",
        "      dec_out = tf.keras.layers.ReLU()(dec_out)\n",
        "\n",
        "  if dense_activation == \"linear\":\n",
        "    dense = TimeDistributed(Dense(features, activation='linear'))\n",
        "  final_out = dense(dec_out)\n",
        "  model = Model(input, final_out)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss=loss_func_choice,\n",
        "                # optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_range),\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mse',tf.keras.metrics.RootMeanSquaredError()])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJWZoLnl0203"
      },
      "outputs": [],
      "source": [
        "model = encoder_decoder_model(params)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AilulNQv44iI"
      },
      "outputs": [],
      "source": [
        "train_set, val_set = prepare_tensors(train=(X_train, y_train), validation=(X_val, y_val), batch_size=params.get('batch_size'), shuffle_buffer_size=shuffle_buffer_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IegjR_I44D5i"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_set, validation_data = val_set, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzCgWq334-fh"
      },
      "outputs": [],
      "source": [
        "#model.save('/content/drive/MyDrive/marjan_multi_step_28Nov_all_metric_120_30step.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = tf.keras.models.load_model('/content/drive/MyDrive/marjan_single_step_26_09_2023')"
      ],
      "metadata": {
        "id": "pvH9FiexE8zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions.shape"
      ],
      "metadata": {
        "id": "5tmA8qFvGrS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7dvRsc06rio"
      },
      "outputs": [],
      "source": [
        "def performance_metrics(col_names, preds, true_val_, ts_date):\n",
        "  test_size = preds.shape[0]\n",
        "  true_val = true_val_.loc[ts_date.reshape(-1)][:test_size].reset_index()\n",
        "  final_out = defaultdict(dict)\n",
        "  date_col = ts_date.reshape(-1)[:test_size]\n",
        "  for feat in col_names:\n",
        "    rmse = mean_squared_error(y_true=true_val[feat], y_pred=preds[feat], squared=False)\n",
        "    mae = mean_absolute_error(y_true=true_val[feat], y_pred=preds[feat])\n",
        "    r2_sc = r2_score(y_true=true_val[feat], y_pred=preds[feat])\n",
        "    mape = mean_absolute_percentage_error(y_true=true_val[feat], y_pred=preds[feat])\n",
        "    print(f\"{feat}\\nMAE: {mae}\\tRMSE: {rmse}\\tR2 Score: {r2_sc}\\tMAPE: {mape}\\n\")\n",
        "    df = pd.DataFrame(data=[date_col, preds[feat]]).T\n",
        "    df = df.rename(columns={0:'timestamp',1:feat})\n",
        "    np_df = df.to_numpy()\n",
        "    eval_metrics = {\"rmse\":rmse, \"mae\":mae, \"r2_score\":r2_sc, \"mape\": mape}\n",
        "    metric_name = feat\n",
        "    meta_d = {\"metric\": eval_metrics, 'values': np_df, 'best_prediction':False}\n",
        "    final_out[metric_name] = meta_d\n",
        "\n",
        "  return final_out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_test), X_test.shape)\n",
        "#print(type(preds), preds.shape)\n",
        "print(type(predictions), predictions.shape)\n",
        "print(type(ts_dates), np.shape(ts_dates))"
      ],
      "metadata": {
        "id": "Qu9hvHt1ls2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlFQw0O-hKjY"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.reset_index()\n",
        "print(type(test_data), test_data.shape)\n",
        "print(type(ts_dates), ts_dates.shape)\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing with multistep"
      ],
      "metadata": {
        "id": "Sxlb_4CfUqDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unscale the predictions\n",
        "print(predictions.shape[0])\n",
        "predictions_ = []\n",
        "X_test_ = []\n",
        "y_test_ = []\n",
        "for i in range(predictions.shape[0]):\n",
        "  p1 = ts_scaler.inverse_transform(predictions[i,:,:])\n",
        "  x1 = ts_scaler.inverse_transform(X_test[i,:,:])\n",
        "  y1 = ts_scaler.inverse_transform(y_test[i,:,:])\n",
        "  predictions_.append(p1)\n",
        "  X_test_.append(x1)\n",
        "  y_test_.append(y1)\n",
        "\n",
        "predictions_ = np.array(predictions_)\n",
        "X_test_ = np.array(X_test_)\n",
        "y_test_ = np.array(y_test_)\n",
        "print(type(predictions_), np.shape(predictions_))\n",
        "print(type(X_test_), np.shape(X_test_))\n",
        "print(type(y_test_), np.shape(y_test_))"
      ],
      "metadata": {
        "id": "YmVrfbBf9M8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.shape, np.shape(predictions[0,:,:]))\n",
        "print(X_test.shape, np.shape(X_test[0,:,:]))\n",
        "#preds = predictions[0,:,:]\n",
        "#trues = X_test[0,:,:]\n",
        "#trues_y = y_test[0,:,:]\n",
        "lst = [i+window_size for i in range(horizon)]\n",
        "count = 0\n",
        "for i,j in enumerate(range(0,predictions_.shape[0],50)):\n",
        "  count+=1\n",
        "  #print(\"i=\", i, \"j=\", j)\n",
        "print(\"count=\", count, round(count/3))\n",
        "figure, ax = plt.subplots(round(count/3), 3, figsize=(15,60))\n",
        "for j, i in enumerate(range(0,predictions_.shape[0],50)):\n",
        "  #print(\"i=\", i)\n",
        "  ax = ax.ravel()\n",
        "  #ax[0][0].set_xlim(0,310)\n",
        "  forecast_values = predictions_[i,:,0]\n",
        "  dataframe_cols = {\"yhat\": np.array(forecast_values)}\n",
        "\n",
        "  upper_bound = np.array(\n",
        "            [\n",
        "                (\n",
        "                        forecast_values[i] + (np.std(forecast_values[:i]) * 3)\n",
        "                )\n",
        "                for i in range(len(forecast_values))\n",
        "            ]\n",
        "        )\n",
        "  upper_bound[0] = np.mean(\n",
        "            forecast_values[0]\n",
        "        )  # to account for no std of a single value\n",
        "  lower_bound = np.array(\n",
        "            [\n",
        "                (\n",
        "                        forecast_values[i] - (np.std(forecast_values[:i]) * 3)\n",
        "                )\n",
        "                for i in range(len(forecast_values))\n",
        "            ]\n",
        "        )\n",
        "  lower_bound[0] = np.mean(\n",
        "            forecast_values[0]\n",
        "        )  # to account for no std of a single value\n",
        "  ub = upper_bound\n",
        "  lb = lower_bound\n",
        "  #fig, ax = plt.subplots(1)\n",
        "  #print(\"shape:\", np.shape(predictions_[i,:,:]), np.shape(predictions_))\n",
        "  ax[j].plot(X_test_[i,:,0], label='GroundTruth')\n",
        "  ax[j].plot(lst, predictions_[i,:,0], label='Prediction for {} metric'.format(multi_data.columns[0]))\n",
        "  ax[j].plot(lst, y_test_[i,:,0], label='True_y')\n",
        "  ax[j].plot(lst, ub, label='Upper Bound')\n",
        "  ax[j].plot(lst, lb, label='Lower Bound'),\n",
        "  ax[j].fill_between(lst, lb, ub, facecolor='bisque', alpha=0.5,\n",
        "                label='std-dev range')\n",
        "  #plt.set_title(test_data.columns[1])\n",
        "  plt.suptitle('Groundtruth and predicted plots for {}'.format(multi_data.columns[0]))\n",
        "  plt.tight_layout()\n",
        "plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "TV-9KF74Utcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions.shape, np.shape(predictions[0,:,:]))\n",
        "print(X_test.shape, np.shape(X_test[0,:,:]))\n",
        "#preds = predictions[0,:,:]\n",
        "#trues = X_test[0,:,:]\n",
        "#trues_y = y_test[0,:,:]\n",
        "for met in range(len(multi_data.columns)):\n",
        "  lst = [i+window_size for i in range(horizon)]\n",
        "  count = 0\n",
        "  for i,j in enumerate(range(0,predictions_.shape[0],50)):\n",
        "    count+=1\n",
        "    #print(\"i=\", i, \"j=\", j)\n",
        "  print(\"count=\", count, round(count/3))\n",
        "  in_range_pred = []\n",
        "  figure, ax = plt.subplots(round(count/3), 3, figsize=(15,60))\n",
        "  for j, i in enumerate(range(0,predictions_.shape[0],50)):\n",
        "    ax = ax.ravel()\n",
        "    #ax[0][0].set_xlim(0,310)\n",
        "    forecast_values = predictions_[i,:,met]\n",
        "    dataframe_cols = {\"yhat\": np.array(forecast_values)}\n",
        "    upper_bound = np.array(\n",
        "            [\n",
        "                (\n",
        "                        forecast_values[i] + (np.std(forecast_values[:i]) * 2)\n",
        "                )\n",
        "                for i in range(len(forecast_values))\n",
        "            ]\n",
        "        )\n",
        "    upper_bound[met] = np.mean(\n",
        "            forecast_values[met]\n",
        "        )  # to account for no std of a single value\n",
        "    lower_bound = np.array(\n",
        "            [\n",
        "                (\n",
        "                        forecast_values[i] - (np.std(forecast_values[:i]) * 2)\n",
        "                )\n",
        "                for i in range(len(forecast_values))\n",
        "            ]\n",
        "        )\n",
        "    lower_bound[met] = np.mean(\n",
        "            forecast_values[met]\n",
        "        )  # to account for no std of a single value\n",
        "    ub = upper_bound\n",
        "    lb = lower_bound\n",
        "    #fig, ax = plt.subplots(1)\n",
        "    #print(\"shape:\", np.shape(predictions_[i,:,:]), np.shape(predictions_))\n",
        "    #if lb <= y_test_[i,:,0] <= ub:\n",
        "    outliercount = 0\n",
        "    valid_count = 0\n",
        "    for tv, lower, upper in zip(y_test_[i,:,met], lb, ub):\n",
        "      if lower <= tv <= upper:\n",
        "        valid_count+=1\n",
        "      else:\n",
        "        outliercount+=1\n",
        "\n",
        "\n",
        "    ax[j].plot(X_test_[i,:,met], label='GroundTruth')\n",
        "    ax[j].plot(lst, predictions_[i,:,met], label='Pred- {} metric'.format(multi_data.columns[met][-30:]))\n",
        "    ax[j].plot(lst, y_test_[i,:,met], label='True_y::Outliers={}'.format(outliercount))\n",
        "    ax[j].plot(lst, ub, label='Upper Bound')\n",
        "    ax[j].plot(lst, lb, label='Lower Bound'),\n",
        "    ax[j].fill_between(lst, lb, ub, facecolor='bisque', alpha=0.5,\n",
        "                label='std-dev range::valid={}'.format(valid_count))\n",
        "    #ax[j].ylabel(outlier_count)\n",
        "    #plt.set_title(test_data.columns[1])\n",
        "    in_range_pred.append(valid_count/horizon)\n",
        "    plt.suptitle('Groundtruth and predicted plots for {}'.format(multi_data.columns[met]))\n",
        "    plt.tight_layout()\n",
        "    ax[j].legend()\n",
        "  print(\"Score for metric {} is :{}\".format(multi_data.columns[met],sum(in_range_pred)/len(in_range_pred)))"
      ],
      "metadata": {
        "id": "oXSduIStrcbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do training on mean(5min resample) -- train on all 6 metric\n",
        "multi_data.columns[0][-30:]"
      ],
      "metadata": {
        "id": "XCC8RTydP5CO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}